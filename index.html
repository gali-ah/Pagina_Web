<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Tema 1: Estad√≠stica B√°sica</title>
</head>
<body>
  <h1>TEMA 1: Estad√≠stica B√°sica</h1>

  <h2>1.1 Conceptos b√°sicos de estad√≠stica</h2>
  <p><strong>Definici√≥n de estad√≠stica:</strong> Es el estudio de c√≥mo recolectar, analizar e interpretar datos para tomar decisiones informadas.</p>
  <p><strong>Teor√≠a de decisi√≥n:</strong> M√©todo para tomar decisiones basado en informaci√≥n y c√°lculos probabil√≠sticos.</p>
  <p><strong>Poblaci√≥n:</strong> Conjunto completo de elementos que se est√°n estudiando, como personas, objetos, o datos.</p>
  <p><strong>Muestra aleatoria:</strong> Subconjunto seleccionado de manera imparcial de la poblaci√≥n total para representarla.</p>
  <p><strong>Par√°metros aleatorios:</strong> Valores que representan caracter√≠sticas de la poblaci√≥n y pueden variar con cada an√°lisis.</p>

  <h2>1.2 Descripci√≥n de datos</h2>
  <p><strong>Datos agrupados y no agrupados:</strong> Datos organizados en categor√≠as o presentados individualmente.</p>
  <p><strong>Frecuencia de clase:</strong> N√∫mero de veces que aparece cada categor√≠a en datos agrupados.</p>
  <p><strong>Frecuencia relativa:</strong> Proporci√≥n de cada categor√≠a respecto al total de datos.</p>
  <p><strong>Punto medio y l√≠mites:</strong> Valor central y valores extremos de cada categor√≠a en datos agrupados.</p>

  <h2>1.3 Medidas de tendencia central y dispersi√≥n</h2>
  <p><strong>Media aritm√©tica:</strong> \( \bar{x} = \frac{\sum_{i=1}^{n} x_i}{n} \)</p>
  <p><strong>Media geom√©trica:</strong> \( GM = \sqrt[n]{x_1 \cdot x_2 \cdot \ldots \cdot x_n} \)</p>
  <p><strong>Media ponderada:</strong> \( \bar{x}_w = \frac{\sum_{i=1}^{n} x_i \cdot w_i}{\sum_{i=1}^{n} w_i} \)</p>
  <p><strong>Mediana:</strong> Valor central cuando los datos est√°n ordenados.</p>
  <p><strong>Moda:</strong> Valor que aparece con mayor frecuencia.</p>
  <p><strong>Varianza:</strong> \( \sigma^2 = \frac{\sum_{i=1}^{n} (x_i - \bar{x})^2}{n} \)</p>

  <h2>1.8 Histogramas</h2>
  <p>Los histogramas son representaciones gr√°ficas de la distribuci√≥n de frecuencias de un conjunto de datos. Aqu√≠ se presentan barras que representan la frecuencia o la densidad de cada intervalo o categor√≠a de datos.</p>
  <h3>Caracter√≠sticas:</h3>
  <ul>
    <li>Muestra la distribuci√≥n de datos agrupados.</li>
    <li>La altura de cada barra representa la frecuencia o densidad de datos en cada intervalo.</li>
    <li>Los intervalos (o bins) son de ancho uniforme y no se superponen.</li>
    <li>Se utiliza para visualizar la forma y la dispersi√≥n de los datos.</li>
  </ul>
  <h3>Uso:</h3>
  <ul>
    <li>Ayuda a identificar la forma general de la distribuci√≥n de los datos (normal, sesgada, etc.).</li>
    <li>Permite identificar la concentraci√≥n de datos en ciertos rangos.</li>
    <li>Es √∫til para comparar varias distribuciones de datos.</li>
  </ul>
  <h3>Construcci√≥n:</h3>
  <ol>
    <li>Se define el n√∫mero de intervalos (bins) y se agrupan los datos en cada intervalo.</li>
    <li>Se calcula la frecuencia de datos en cada intervalo.</li>
    <li>Se dibujan barras rectangulares donde el ancho representa el intervalo y la altura representa la frecuencia.</li>
  </ol>
  <p><strong>Ejemplo de f√≥rmula:</strong> Para datos agrupados en intervalos, la altura de cada barra se calcula como la frecuencia dividida por el ancho del intervalo.</p>
</body>
</html>

<title>TEMA 2: Fundamentos de la Teor√≠a de Probabilidad</title>
</head>
<body>
  <h1>TEMA 2: Fundamentos de la Teor√≠a de Probabilidad</h1>

  <h2>2. Fundamentos de la Teor√≠a de Probabilidad</h2>

  <h3>2.1 T√©cnicas de Conteo</h3>

  <h4>2.1.1 Principio Aditivo</h4>
  <p>El principio aditivo establece que si un evento puede ocurrir de <em>A</em> maneras diferentes o de <em>B</em> maneras diferentes, entonces el n√∫mero total de maneras en que puede ocurrir es <em>A + B</em>.</p>
  <p><strong>Uso:</strong> Se utiliza para contar el n√∫mero total de resultados posibles cuando se pueden dividir los eventos en casos mutuamente excluyentes.</p>

  <h4>2.1.2 Principio Multiplicativo</h4>
  <p>El principio multiplicativo establece que si un evento puede ocurrir de <em>A</em> maneras diferentes y, para cada una de esas <em>A</em> maneras, un segundo evento puede ocurrir de <em>B</em> maneras diferentes, entonces el n√∫mero total de maneras en que pueden ocurrir ambos eventos es <em>A √ó B</em>.</p>
  <p><strong>Uso:</strong> Se aplica cuando se desea determinar el n√∫mero total de resultados posibles para una secuencia de eventos independientes.</p>

  <h4>2.1.3 Notaci√≥n Factorial</h4>
  <p>La notaci√≥n factorial, denotada como <em>n!</em>, representa el producto de todos los n√∫meros enteros positivos desde 1 hasta <em>n</em>.</p>
  <p><em>n!</em> = <em>n √ó (n ‚àí 1) √ó (n ‚àí 2) √ó ... √ó 1</em></p>
  <p><strong>Uso:</strong> Se utiliza en problemas de permutaciones y combinaciones para calcular el n√∫mero de arreglos y selecciones posibles.</p>

  <h4>2.1.4 Permutaciones</h4>
  <p>Las permutaciones son el n√∫mero de formas en que se pueden ordenar los elementos de un conjunto. Se denota como <em>P(n, k)</em> y se calcula como:</p>
  <p><em>P(n, k)</em> = <em>(n!)/(n ‚àí k)!</em></p>
  <p><strong>Uso:</strong> Se aplica cuando se desea contar el n√∫mero de arreglos ordenados de <em>k</em> elementos tomados de un conjunto de <em>n</em> elementos.</p>

  <h4>2.1.5 Combinaciones</h4>
  <p>Las combinaciones son el n√∫mero de formas en que se pueden seleccionar <em>k</em> elementos de un conjunto de <em>n</em> elementos sin tener en cuenta el orden. Se denota como <em>C(n, k)</em> y se calcula como:</p>
  <p><em>C(n, k)</em> = <em>(n!)/(k! √ó (n ‚àí k)!)</em></p>
  <p><strong>Uso:</strong> Se utiliza cuando el orden de selecci√≥n no es importante, como en la formaci√≥n de grupos o comit√©s.</p>

  <h4>2.1.6 Diagrama de √Årbol</h4>
  <p>El diagrama de √°rbol es una representaci√≥n gr√°fica que muestra todas las posibles secuencias de eventos o resultados de un experimento aleatorio.</p>
  <p><strong>Uso:</strong> Se utiliza para visualizar y calcular las probabilidades de m√∫ltiples eventos secuenciales en experimentos probabil√≠sticos.</p>

  <h4>2.1.7 Teorema del Binomio</h4>
  <p>El teorema del binomio describe la expansi√≥n de la expresi√≥n <em>(a + b)^n</em> en una suma de t√©rminos que involucran potencias y coeficientes binomiales.</p>
  <p><em>(a + b)^n = ‚àë<sub>k=0</sub><sup>n</sup> C(n, k) a<sup>n‚àík</sup> b<sup>k</sup></em></p>
  <p><strong>Uso:</strong> Se aplica en problemas donde se necesitan calcular probabilidades o distribuciones binomiales, como en experimentos de √©xito-fracaso repetidos.</p>

  <h3>2.2 Teor√≠a Elemental de Probabilidad</h3>
  <p>La teor√≠a elemental de probabilidad estudia conceptos b√°sicos como el espacio muestral, los eventos, la probabilidad de eventos simples y compuestos, y las operaciones entre eventos.</p>

  <h3>2.3 Probabilidad de Eventos</h3>
  <p><strong>Espacio Muestral:</strong> Es el conjunto de todos los posibles resultados de un experimento aleatorio.</p>
  <p><strong>Evento en Probabilidad:</strong> Es cualquier subconjunto del espacio muestral.</p>
  <p><strong>Simbolog√≠a:</strong> Incluye notaciones como <em>P(A)</em> para la probabilidad del evento <em>A</em>, <em>P(A‚à£B)</em> para la probabilidad de <em>A</em> dado <em>B</em>, y s√≠mbolos como <em>‚à™</em> (uni√≥n) y <em>‚à©</em> (intersecci√≥n).</p>
  <p><strong>Uni√≥n e Intersecci√≥n de Eventos:</strong> La uni√≥n de eventos <em>A</em> y <em>B</em> es el evento que ocurre cuando ocurre al menos uno de los dos eventos. La intersecci√≥n de <em>A</em> y <em>B</em> es el evento que ocurre cuando ambos eventos ocurren simult√°neamente.</p>
  <p><strong>Diagramas de Venn:</strong> Son representaciones gr√°ficas que muestran los subconjuntos de un espacio muestral y las relaciones entre ellos.</p>

  <h3>2.4 Probabilidad con T√©cnicas de Conteo</h3>
  <p><strong>Axiomas de Probabilidad:</strong> Son las reglas fundamentales que debe cumplir una funci√≥n de probabilidad, como que la probabilidad de un evento sea un n√∫mero entre 0 y 1.</p>
  <p><strong>Teoremas de Probabilidad:</strong> Son resultados que se deducen de los axiomas de probabilidad, como el teorema de la probabilidad total y el teorema de Bayes.</p>

  <h3>2.5 Probabilidad Condicional</h3>
  <p><strong>Probabilidad Condicional:</strong> Es la probabilidad de que ocurra un evento dado que otro evento ya ha ocurrido.</p>
  <p><strong>Eventos Dependientes e Independientes:</strong> Eventos dependientes son aquellos cuya ocurrencia est√° influenciada por la ocurrencia de otro evento, mientras que eventos independientes son aquellos cuya ocurrencia no se ve afectada por la ocurrencia de otro evento.</p>

  <h3>2.6 Ley Multiplicativa de Probabilidad</h3>
  <p>La ley multiplicativa establece que la probabilidad de que ocurran dos eventos independientes es el producto de las probabilidades individuales de cada evento.</p>

  <h3>2.7 Regla de Bayes</h3>
  <p>La regla de Bayes es un teorema que permite calcular la probabilidad de un evento, dado que se conoce la probabilidad de otro evento relacionado.</p>
</body>
</html>

<h1>TEMA 3: Variables Aleatorias</h1>


  <h2>3. Variables Aleatorias</h2>
  <a href="https://www.loom.com/share/26a97c70b3a049158ff88d6c2651268b?sid=2197f1e9-2eee-4c3e-ad2a-14995195ca70" target="_blank">Introducci√≥n a Variables Aleatorias Continuas en Probabilidad y Estad√≠stica | Loom</a>

  <h3>3.1 Variables Aleatorias Discretas</h3> <a href="https://www.loom.com/share/158b1751afbb4527b0d287126bd876e0?sid=4b748aac-9c02-4830-88b0-e15e97e32854" target="_blank">Variables Aleatorias Discretas y Distribuciones de Probabilidad üé≤ | Loom</a>

  <h4>3.1.1 Distribuci√≥n de Probabilidad en Forma General</h4>
  <p>La distribuci√≥n de probabilidad de una variable aleatoria discreta especifica las probabilidades asociadas con cada valor posible que puede tomar la variable. Se define mediante una funci√≥n <em>P(X = xi) = pi</em>, donde <em>X</em> es la variable aleatoria y <em>xi</em> son los valores que puede tomar, con <em>pi = P(X = xi)</em>.</p>
  <p><strong>Uso:</strong> Se utiliza para modelar fen√≥menos discretos como lanzamientos de dados o √©xitos/fallos en experimentos.</p>

  <h4>3.1.2 Valor Esperado</h4>
  <p>El valor esperado, o esperanza matem√°tica, de una variable aleatoria discreta <em>X</em> se calcula como la suma ponderada de todos los posibles valores que puede tomar la variable, cada uno multiplicado por su probabilidad correspondiente:</p>
  <p><em>E(X) = ‚àë xi ‚ãÖ pi</em></p>
  <p><strong>Uso:</strong> Representa el valor promedio que se espera obtener en un gran n√∫mero de repeticiones del experimento aleatorio.</p>

  <h4>3.1.3 Varianza y Desviaci√≥n Est√°ndar</h4>
  <p>La varianza y la desviaci√≥n est√°ndar miden la dispersi√≥n de los valores de una variable aleatoria respecto a su media.</p>
  <p><strong>Varianza:</strong> Se calcula como la suma de los cuadrados de las diferencias entre cada valor posible y el valor esperado, ponderado por sus probabilidades.</p>
  <p><strong>Desviaci√≥n Est√°ndar:</strong> Es la ra√≠z cuadrada positiva de la varianza.</p>
  <p><strong>Uso:</strong> Indican qu√© tan dispersos est√°n los valores respecto a su media esperada.</p>

  <h4>3.1.4 Funci√≥n Acumulada</h4>
  <p>La funci√≥n acumulada <em>F(x)</em> de una variable aleatoria discreta <em>X</em> se define como la probabilidad de que la variable aleatoria tome un valor menor o igual a <em>x</em>:</p>
  <p><em>F(x) = P(X ‚â§ x) = ‚àë xi ‚â§ x pi</em></p>
  <p><strong>Uso:</strong> Permite calcular probabilidades acumuladas hasta un valor dado de la variable aleatoria.</p>

  <h3>3.2 Variables Aleatorias Continuas</h3>

  <h4>3.2.1 Distribuci√≥n de Probabilidad en Forma General</h4>
  <p>La distribuci√≥n de probabilidad de una variable aleatoria continua se describe mediante una funci√≥n de densidad de probabilidad <em>f(x)</em>, donde <em>f(x) ‚â• 0</em> para todo <em>x</em> y <em>‚à´‚àí‚àû‚àû f(x) dx = 1</em>.</p>
  <p><strong>Uso:</strong> Modela fen√≥menos como el tiempo de espera, medidas f√≠sicas, entre otros, donde los valores pueden tomar cualquier valor dentro de un rango continuo.</p>

  <h4>3.2.2 Valor Esperado</h4>
  <p>El valor esperado de una variable aleatoria continua <em>X</em> se calcula como la integral de <em>x</em> ponderada por su funci√≥n de densidad de probabilidad:</p>
  <p><em>E(X) = ‚à´‚àí‚àû‚àû x ‚ãÖ f(x) dx</em></p>
  <p><strong>Uso:</strong> Representa el promedio ponderado de los posibles valores que puede tomar la variable aleatoria continua.</p>

  <h4>3.2.3 Varianza y Desviaci√≥n Est√°ndar</h4>
  <p>La varianza y la desviaci√≥n est√°ndar para una variable aleatoria continua se calculan de manera similar a las variables discretas, pero utilizando la funci√≥n de densidad de probabilidad.</p>
  <p><strong>Varianza:</strong> Se calcula como la integral de los cuadrados de las diferencias entre cada valor y el valor esperado, ponderado por la funci√≥n de densidad de probabilidad.</p>
  <p><strong>Desviaci√≥n Est√°ndar:</strong> Es la ra√≠z cuadrada positiva de la varianza.</p>

  <h4>3.2.4 Funci√≥n Acumulada</h4>
  <p>La funci√≥n acumulada <em>F(x)</em> de una variable aleatoria continua <em>X</em> se define como la integral de la funci√≥n de densidad de probabilidad hasta <em>x</em>:</p>
  <p><em>F(x) = P(X ‚â§ x) = ‚à´‚àí‚àûx f(t) dt</em></p>
  <p><strong>Uso:</strong> Permite calcular probabilidades acumuladas hasta un valor dado de la variable aleatoria continua.</p>

  <h4>3.2.5 C√°lculos de Probabilidad</h4>
  <p>Para calcular la probabilidad de que una variable aleatoria continua caiga en un intervalo espec√≠fico [<em>a, b</em>], se utiliza la funci√≥n de densidad de probabilidad:</p>
  <p><em>P(a ‚â§ X ‚â§ b) = ‚à´ab f(x) dx</em></p>
  <p><strong>Uso:</strong> Determina la probabilidad de que la variable aleatoria caiga dentro de un rango espec√≠fico de valores.</p>
</body>
</html>

<title>Tema 4: Distribuciones de Probabilidad</title>
<style>
  body {
    font-family: Arial, sans-serif;
    line-height: 1.6;
    margin: 20px;
  }
  h2 {
    color: #333;
  }
  p {
    margin-bottom: 15px;
  }
  .section {
    margin-bottom: 30px;
    border-bottom: 1px solid #ccc;
    padding-bottom: 20px;
  }
</style>
</head>
<body>
<h1>Tema 4: Distribuciones de Probabilidad</h1>

<div class="section">
  <h2>4.1 Funci√≥n de Probabilidad</h2>
  <p>La funci√≥n de probabilidad describe la relaci√≥n entre los valores de una variable aleatoria y sus probabilidades correspondientes en el contexto de una distribuci√≥n de probabilidad espec√≠fica.</p>
  <p><strong>Explicaci√≥n:</strong> Para una variable aleatoria discreta \( X \), la funci√≥n de probabilidad \( P(X=x) \) asigna probabilidades a cada valor \( x \) que puede tomar \( X \).</p>
</div>

<div class="section">
  <h2>4.2 Distribuci√≥n Binomial</h2>
  <p>La distribuci√≥n binomial modela el n√∫mero de √©xitos en una secuencia de \( n \) ensayos independientes, donde cada ensayo tiene exactamente dos resultados posibles: √©xito o fracaso.</p>
  <p><strong>Explicaci√≥n:</strong> La probabilidad de exactamente \( k \) √©xitos en \( n \) ensayos con probabilidad de √©xito \( p \) est√° dada por:</p>
  <p>\[ P(X=k) = \binom{n}{k} p^k (1-p)^{n-k} \]</p>
  <p>donde \( \binom{n}{k} \) es el coeficiente binomial que representa el n√∫mero de formas de elegir \( k \) √©xitos entre \( n \) ensayos.</p>
  <a href="https://www.loom.com/share/e5d4ea175f2a4e09832f562e878af369?sid=f7238aee-2a2a-4313-a8f5-7a55e24e37fd" target="_blank">Resoluci√≥n de Ejercicio de Probabilidad y Estad√≠stica en Python | Loom</a>
</div>

<div class="section">
  <h2>4.3 Distribuci√≥n Hipergeom√©trica</h2>
  <p>La distribuci√≥n hipergeom√©trica modela el n√∫mero de √©xitos en una muestra de tama√±o \( n \) extra√≠da sin reemplazo de una poblaci√≥n finita de tama√±o \( N \), donde \( K \) son los elementos exitosos en la poblaci√≥n.</p>
  <p><strong>Explicaci√≥n:</strong> La probabilidad de exactamente \( k \) √©xitos en la muestra est√° dada por:</p>
  <p>\[ P(X=k) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}} \]</p>
  <p>donde \( \binom{K}{k} \) es el n√∫mero de formas de elegir \( k \) √©xitos de \( K \) elementos y \( \binom{N-K}{n-k} \) es el n√∫mero de formas de elegir \( n-k \) fallos de \( N-K \) elementos.</p>
</div>

<div class="section">
  <h2>4.4 Distribuci√≥n de Poisson</h2>
  <p>La distribuci√≥n de Poisson modela el n√∫mero de eventos que ocurren en un intervalo de tiempo o espacio fijo, dado que los eventos ocurren a una tasa promedio constante y de manera independiente.</p>
  <p><strong>Explicaci√≥n:</strong> La probabilidad de observar \( k \) eventos en un intervalo est√° dada por:</p>
  <p>\[ P(X=k) = \frac{\lambda^k e^{-\lambda}}{k!} \]</p>
  <p>donde \( \lambda \) es la tasa promedio de eventos por intervalo.</p>
</div>

<div class="section">
  <h2>4.5 Distribuci√≥n Normal</h2>
  <p>La distribuci√≥n normal, o gaussiana, es una de las distribuciones m√°s importantes en estad√≠stica. Describe la distribuci√≥n de una variable continua que es sim√©trica alrededor de su media, caracterizada por su media \( \mu \) y desviaci√≥n est√°ndar \( \sigma \).</p>
  <p><strong>Explicaci√≥n:</strong> La funci√≥n de densidad de probabilidad de una distribuci√≥n normal est√° dada por:</p>
  <p>\[ f(x) = \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x-\mu)^2}{2 \sigma^2}} \]</p>
</div>

<div class="section">
  <h2>4.6 Distribuci√≥n T-Student</h2>
  <p>La distribuci√≥n T-Student se utiliza principalmente cuando el tama√±o de la muestra es peque√±o y se desconoce la desviaci√≥n est√°ndar de la poblaci√≥n. Se utiliza en inferencia estad√≠stica para estimar intervalos de confianza y pruebas de hip√≥tesis.</p>
  <p><strong>Explicaci√≥n:</strong> La funci√≥n de densidad de probabilidad de la distribuci√≥n T-Student con \( \nu \) grados de libertad est√° dada por:</p>
  <p>\[ f(t) = \frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu \pi} \, \Gamma\left(\frac{\nu}{2}\right)} \left(1 + \frac{t^2}{\nu}\right)^{-\frac{\nu+1}{2}} \]</p>
</div>

<div class="section">
  <h2>4.7 Distribuci√≥n Chi Cuadrada</h2>
  <p>La distribuci√≥n Chi cuadrada se utiliza principalmente en pruebas de hip√≥tesis y estimaci√≥n de intervalos de confianza para la varianza de una poblaci√≥n normalmente distribuida.</p>
  <p><strong>Explicaci√≥n:</strong> La funci√≥n de densidad de probabilidad de una distribuci√≥n Chi cuadrada con \( \nu \) grados de libertad est√° dada por:</p>
  <p>\[ f(x) = \frac{1}{2^{\frac{\nu}{2}} \Gamma\left(\frac{\nu}{2}\right)} x^{\frac{\nu}{2}-1} e^{-\frac{x}{2}} \]</p>
</div>

<div class="section">
  <h2>4.8 Distribuci√≥n F</h2>
  <p>La distribuci√≥n F se utiliza en an√°lisis de la varianza (ANOVA) y en pruebas de hip√≥tesis sobre la igualdad de varianzas de dos poblaciones normales.</p>
  <p><strong>Explicaci√≥n:</strong> La funci√≥n de densidad de probabilidad de una distribuci√≥n F con \( d_1 \) grados de libertad en el numerador y \( d_2 \) grados de libertad en el denominador est√° dada por:</p>
  <p>\[ f(x) = \frac{\Gamma\left(\frac{d_1 + d_2}{2}\right) \left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}} x^{\frac{d_1}{2} - 1}}{\Gamma\left(\frac{d_1}{2}\right) \Gamma\left(\frac{d_2}{2}\right) \left(1 + \frac{d_1 x}{d_2}\right)^{\frac{d_1 + d_2}{2}} } \]</p>
</div>

</body>
</html>

<title>Tema 5: Regresi√≥n Lineal</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
        }
        h1, h2, h3 {
            color: #333;
        }
        .section {
            margin-bottom: 20px;
        }
        .subsection {
            margin-bottom: 10px;
        }
        .explanation {
            margin-left: 20px;
        }
    </style>
</head>
<body>
    <h1>TEMA 5: Regresi√≥n Lineal</h1>

    <div class="section">
        <h2>5.1 Regresi√≥n y Correlaci√≥n</h2>

        <div class="subsection">
            <h3>5.1.1 Diagrama de Dispersi√≥n</h3>
            <div class="explanation">
                <p>Un diagrama de dispersi√≥n es una representaci√≥n gr√°fica de pares de datos (x, y), donde cada punto representa una observaci√≥n. Es √∫til para visualizar la relaci√≥n entre dos variables y detectar patrones como tendencias, agrupaciones o dispersi√≥n.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.2 Regresi√≥n Lineal Simple</h3>
            <div class="explanation">
                <p>La regresi√≥n lineal simple modela la relaci√≥n entre una variable independiente <em>x</em> y una variable dependiente <em>y</em> mediante una ecuaci√≥n lineal de la forma <em>y = Œ≤‚ÇÄ + Œ≤‚ÇÅx + œµ</em>, donde <em>Œ≤‚ÇÄ</em> y <em>Œ≤‚ÇÅ</em> son los coeficientes de la regresi√≥n y <em>œµ</em> es el t√©rmino de error.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.3 Correlaci√≥n</h3>
            <div class="explanation">
                <p>La correlaci√≥n cuantifica la fuerza y direcci√≥n de la relaci√≥n lineal entre dos variables. El coeficiente de correlaci√≥n de Pearson <em>r</em> es una medida com√∫n que var√≠a entre -1 y 1, donde 1 indica una correlaci√≥n positiva perfecta, -1 una correlaci√≥n negativa perfecta y 0 una falta de correlaci√≥n lineal.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.4 Determinaci√≥n y An√°lisis de los Coeficientes de Correlaci√≥n y de Determinaci√≥n</h3>
            <div class="explanation">
                <p>El coeficiente de determinaci√≥n <em>R¬≤</em> es una medida que indica qu√© porcentaje de la variabilidad de la variable dependiente puede ser explicada por la variable independiente en el modelo de regresi√≥n. Se calcula como <em>R¬≤ = 1 - (SSres / SStot)</em>, donde <em>SSres</em> es la suma de los cuadrados de los residuos y <em>SStot</em> es la suma total de los cuadrados.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.5 Distribuci√≥n Normal Bidimensional</h3>
            <div class="explanation">
                <p>La distribuci√≥n normal bidimensional describe la distribuci√≥n conjunta de dos variables aleatorias continuas, donde cada variable sigue una distribuci√≥n normal univariada. La funci√≥n de densidad de probabilidad bidimensional se define en t√©rminos de la media, la varianza y el coeficiente de correlaci√≥n entre las dos variables.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.6 Intervalos de Confianza y Pruebas para el Coeficiente de Correlaci√≥n</h3>
            <div class="explanation">
                <p>Los intervalos de confianza para el coeficiente de correlaci√≥n <em>r</em> permiten estimar el rango plausible de valores para <em>r</em> en la poblaci√≥n. Las pruebas de hip√≥tesis se utilizan para determinar si el coeficiente de correlaci√≥n observado es estad√≠sticamente significativo.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.7 Errores de Medici√≥n</h3>
            <div class="explanation">
                <p>Los errores de medici√≥n son discrepancias entre el valor medido de una variable y su valor verdadero. En el contexto de la regresi√≥n lineal, los errores de medici√≥n afectan la precisi√≥n del modelo y pueden introducir sesgos y errores est√°ndar.</p>
            </div>
        </div>

    </div>

</body>
</html>