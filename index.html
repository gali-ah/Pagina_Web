<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Tema 1: Estadística Básica</title>
</head>
<body>
  <h1>TEMA 1: Estadística Básica</h1>

  <h2>1.1 Conceptos básicos de estadística</h2>
  <p><strong>Definición de estadística:</strong> Es el estudio de cómo recolectar, analizar e interpretar datos para tomar decisiones informadas.</p>
  <p><strong>Teoría de decisión:</strong> Método para tomar decisiones basado en información y cálculos probabilísticos.</p>
  <p><strong>Población:</strong> Conjunto completo de elementos que se están estudiando, como personas, objetos, o datos.</p>
  <p><strong>Muestra aleatoria:</strong> Subconjunto seleccionado de manera imparcial de la población total para representarla.</p>
  <p><strong>Parámetros aleatorios:</strong> Valores que representan características de la población y pueden variar con cada análisis.</p>

  <h2>1.2 Descripción de datos</h2>
  <p><strong>Datos agrupados y no agrupados:</strong> Datos organizados en categorías o presentados individualmente.</p>
  <p><strong>Frecuencia de clase:</strong> Número de veces que aparece cada categoría en datos agrupados.</p>
  <p><strong>Frecuencia relativa:</strong> Proporción de cada categoría respecto al total de datos.</p>
  <p><strong>Punto medio y límites:</strong> Valor central y valores extremos de cada categoría en datos agrupados.</p>

  <h2>1.3 Medidas de tendencia central y dispersión</h2>
  <p><strong>Media aritmética:</strong> \( \bar{x} = \frac{\sum_{i=1}^{n} x_i}{n} \)</p>
  <p><strong>Media geométrica:</strong> \( GM = \sqrt[n]{x_1 \cdot x_2 \cdot \ldots \cdot x_n} \)</p>
  <p><strong>Media ponderada:</strong> \( \bar{x}_w = \frac{\sum_{i=1}^{n} x_i \cdot w_i}{\sum_{i=1}^{n} w_i} \)</p>
  <p><strong>Mediana:</strong> Valor central cuando los datos están ordenados.</p>
  <p><strong>Moda:</strong> Valor que aparece con mayor frecuencia.</p>
  <p><strong>Varianza:</strong> \( \sigma^2 = \frac{\sum_{i=1}^{n} (x_i - \bar{x})^2}{n} \)</p>

  <h2>1.8 Histogramas</h2>
  <p>Los histogramas son representaciones gráficas de la distribución de frecuencias de un conjunto de datos. Aquí se presentan barras que representan la frecuencia o la densidad de cada intervalo o categoría de datos.</p>
  <h3>Características:</h3>
  <ul>
    <li>Muestra la distribución de datos agrupados.</li>
    <li>La altura de cada barra representa la frecuencia o densidad de datos en cada intervalo.</li>
    <li>Los intervalos (o bins) son de ancho uniforme y no se superponen.</li>
    <li>Se utiliza para visualizar la forma y la dispersión de los datos.</li>
  </ul>
  <h3>Uso:</h3>
  <ul>
    <li>Ayuda a identificar la forma general de la distribución de los datos (normal, sesgada, etc.).</li>
    <li>Permite identificar la concentración de datos en ciertos rangos.</li>
    <li>Es útil para comparar varias distribuciones de datos.</li>
  </ul>
  <h3>Construcción:</h3>
  <ol>
    <li>Se define el número de intervalos (bins) y se agrupan los datos en cada intervalo.</li>
    <li>Se calcula la frecuencia de datos en cada intervalo.</li>
    <li>Se dibujan barras rectangulares donde el ancho representa el intervalo y la altura representa la frecuencia.</li>
  </ol>
  <p><strong>Ejemplo de fórmula:</strong> Para datos agrupados en intervalos, la altura de cada barra se calcula como la frecuencia dividida por el ancho del intervalo.</p>
</body>
</html>

<title>TEMA 2: Fundamentos de la Teoría de Probabilidad</title>
</head>
<body>
  <h1>TEMA 2: Fundamentos de la Teoría de Probabilidad</h1>

  <h2>2. Fundamentos de la Teoría de Probabilidad</h2>

  <h3>2.1 Técnicas de Conteo</h3>

  <h4>2.1.1 Principio Aditivo</h4>
  <p>El principio aditivo establece que si un evento puede ocurrir de <em>A</em> maneras diferentes o de <em>B</em> maneras diferentes, entonces el número total de maneras en que puede ocurrir es <em>A + B</em>.</p>
  <p><strong>Uso:</strong> Se utiliza para contar el número total de resultados posibles cuando se pueden dividir los eventos en casos mutuamente excluyentes.</p>

  <h4>2.1.2 Principio Multiplicativo</h4>
  <p>El principio multiplicativo establece que si un evento puede ocurrir de <em>A</em> maneras diferentes y, para cada una de esas <em>A</em> maneras, un segundo evento puede ocurrir de <em>B</em> maneras diferentes, entonces el número total de maneras en que pueden ocurrir ambos eventos es <em>A × B</em>.</p>
  <p><strong>Uso:</strong> Se aplica cuando se desea determinar el número total de resultados posibles para una secuencia de eventos independientes.</p>

  <h4>2.1.3 Notación Factorial</h4>
  <p>La notación factorial, denotada como <em>n!</em>, representa el producto de todos los números enteros positivos desde 1 hasta <em>n</em>.</p>
  <p><em>n!</em> = <em>n × (n − 1) × (n − 2) × ... × 1</em></p>
  <p><strong>Uso:</strong> Se utiliza en problemas de permutaciones y combinaciones para calcular el número de arreglos y selecciones posibles.</p>

  <h4>2.1.4 Permutaciones</h4>
  <p>Las permutaciones son el número de formas en que se pueden ordenar los elementos de un conjunto. Se denota como <em>P(n, k)</em> y se calcula como:</p>
  <p><em>P(n, k)</em> = <em>(n!)/(n − k)!</em></p>
  <p><strong>Uso:</strong> Se aplica cuando se desea contar el número de arreglos ordenados de <em>k</em> elementos tomados de un conjunto de <em>n</em> elementos.</p>

  <h4>2.1.5 Combinaciones</h4>
  <p>Las combinaciones son el número de formas en que se pueden seleccionar <em>k</em> elementos de un conjunto de <em>n</em> elementos sin tener en cuenta el orden. Se denota como <em>C(n, k)</em> y se calcula como:</p>
  <p><em>C(n, k)</em> = <em>(n!)/(k! × (n − k)!)</em></p>
  <p><strong>Uso:</strong> Se utiliza cuando el orden de selección no es importante, como en la formación de grupos o comités.</p>

  <h4>2.1.6 Diagrama de Árbol</h4>
  <p>El diagrama de árbol es una representación gráfica que muestra todas las posibles secuencias de eventos o resultados de un experimento aleatorio.</p>
  <p><strong>Uso:</strong> Se utiliza para visualizar y calcular las probabilidades de múltiples eventos secuenciales en experimentos probabilísticos.</p>

  <h4>2.1.7 Teorema del Binomio</h4>
  <p>El teorema del binomio describe la expansión de la expresión <em>(a + b)^n</em> en una suma de términos que involucran potencias y coeficientes binomiales.</p>
  <p><em>(a + b)^n = ∑<sub>k=0</sub><sup>n</sup> C(n, k) a<sup>n−k</sup> b<sup>k</sup></em></p>
  <p><strong>Uso:</strong> Se aplica en problemas donde se necesitan calcular probabilidades o distribuciones binomiales, como en experimentos de éxito-fracaso repetidos.</p>

  <h3>2.2 Teoría Elemental de Probabilidad</h3>
  <p>La teoría elemental de probabilidad estudia conceptos básicos como el espacio muestral, los eventos, la probabilidad de eventos simples y compuestos, y las operaciones entre eventos.</p>

  <h3>2.3 Probabilidad de Eventos</h3>
  <p><strong>Espacio Muestral:</strong> Es el conjunto de todos los posibles resultados de un experimento aleatorio.</p>
  <p><strong>Evento en Probabilidad:</strong> Es cualquier subconjunto del espacio muestral.</p>
  <p><strong>Simbología:</strong> Incluye notaciones como <em>P(A)</em> para la probabilidad del evento <em>A</em>, <em>P(A∣B)</em> para la probabilidad de <em>A</em> dado <em>B</em>, y símbolos como <em>∪</em> (unión) y <em>∩</em> (intersección).</p>
  <p><strong>Unión e Intersección de Eventos:</strong> La unión de eventos <em>A</em> y <em>B</em> es el evento que ocurre cuando ocurre al menos uno de los dos eventos. La intersección de <em>A</em> y <em>B</em> es el evento que ocurre cuando ambos eventos ocurren simultáneamente.</p>
  <p><strong>Diagramas de Venn:</strong> Son representaciones gráficas que muestran los subconjuntos de un espacio muestral y las relaciones entre ellos.</p>

  <h3>2.4 Probabilidad con Técnicas de Conteo</h3>
  <p><strong>Axiomas de Probabilidad:</strong> Son las reglas fundamentales que debe cumplir una función de probabilidad, como que la probabilidad de un evento sea un número entre 0 y 1.</p>
  <p><strong>Teoremas de Probabilidad:</strong> Son resultados que se deducen de los axiomas de probabilidad, como el teorema de la probabilidad total y el teorema de Bayes.</p>

  <h3>2.5 Probabilidad Condicional</h3>
  <p><strong>Probabilidad Condicional:</strong> Es la probabilidad de que ocurra un evento dado que otro evento ya ha ocurrido.</p>
  <p><strong>Eventos Dependientes e Independientes:</strong> Eventos dependientes son aquellos cuya ocurrencia está influenciada por la ocurrencia de otro evento, mientras que eventos independientes son aquellos cuya ocurrencia no se ve afectada por la ocurrencia de otro evento.</p>

  <h3>2.6 Ley Multiplicativa de Probabilidad</h3>
  <p>La ley multiplicativa establece que la probabilidad de que ocurran dos eventos independientes es el producto de las probabilidades individuales de cada evento.</p>

  <h3>2.7 Regla de Bayes</h3>
  <p>La regla de Bayes es un teorema que permite calcular la probabilidad de un evento, dado que se conoce la probabilidad de otro evento relacionado.</p>
</body>
</html>

<h1>TEMA 3: Variables Aleatorias</h1>

  <h2>3. Variables Aleatorias</h2>

  <h3>3.1 Variables Aleatorias Discretas</h3>

  <h4>3.1.1 Distribución de Probabilidad en Forma General</h4>
  <p>La distribución de probabilidad de una variable aleatoria discreta especifica las probabilidades asociadas con cada valor posible que puede tomar la variable. Se define mediante una función <em>P(X = xi) = pi</em>, donde <em>X</em> es la variable aleatoria y <em>xi</em> son los valores que puede tomar, con <em>pi = P(X = xi)</em>.</p>
  <p><strong>Uso:</strong> Se utiliza para modelar fenómenos discretos como lanzamientos de dados o éxitos/fallos en experimentos.</p>

  <h4>3.1.2 Valor Esperado</h4>
  <p>El valor esperado, o esperanza matemática, de una variable aleatoria discreta <em>X</em> se calcula como la suma ponderada de todos los posibles valores que puede tomar la variable, cada uno multiplicado por su probabilidad correspondiente:</p>
  <p><em>E(X) = ∑ xi ⋅ pi</em></p>
  <p><strong>Uso:</strong> Representa el valor promedio que se espera obtener en un gran número de repeticiones del experimento aleatorio.</p>

  <h4>3.1.3 Varianza y Desviación Estándar</h4>
  <p>La varianza y la desviación estándar miden la dispersión de los valores de una variable aleatoria respecto a su media.</p>
  <p><strong>Varianza:</strong> Se calcula como la suma de los cuadrados de las diferencias entre cada valor posible y el valor esperado, ponderado por sus probabilidades.</p>
  <p><strong>Desviación Estándar:</strong> Es la raíz cuadrada positiva de la varianza.</p>
  <p><strong>Uso:</strong> Indican qué tan dispersos están los valores respecto a su media esperada.</p>

  <h4>3.1.4 Función Acumulada</h4>
  <p>La función acumulada <em>F(x)</em> de una variable aleatoria discreta <em>X</em> se define como la probabilidad de que la variable aleatoria tome un valor menor o igual a <em>x</em>:</p>
  <p><em>F(x) = P(X ≤ x) = ∑ xi ≤ x pi</em></p>
  <p><strong>Uso:</strong> Permite calcular probabilidades acumuladas hasta un valor dado de la variable aleatoria.</p>

  <h3>3.2 Variables Aleatorias Continuas</h3>

  <h4>3.2.1 Distribución de Probabilidad en Forma General</h4>
  <p>La distribución de probabilidad de una variable aleatoria continua se describe mediante una función de densidad de probabilidad <em>f(x)</em>, donde <em>f(x) ≥ 0</em> para todo <em>x</em> y <em>∫−∞∞ f(x) dx = 1</em>.</p>
  <p><strong>Uso:</strong> Modela fenómenos como el tiempo de espera, medidas físicas, entre otros, donde los valores pueden tomar cualquier valor dentro de un rango continuo.</p>

  <h4>3.2.2 Valor Esperado</h4>
  <p>El valor esperado de una variable aleatoria continua <em>X</em> se calcula como la integral de <em>x</em> ponderada por su función de densidad de probabilidad:</p>
  <p><em>E(X) = ∫−∞∞ x ⋅ f(x) dx</em></p>
  <p><strong>Uso:</strong> Representa el promedio ponderado de los posibles valores que puede tomar la variable aleatoria continua.</p>

  <h4>3.2.3 Varianza y Desviación Estándar</h4>
  <p>La varianza y la desviación estándar para una variable aleatoria continua se calculan de manera similar a las variables discretas, pero utilizando la función de densidad de probabilidad.</p>
  <p><strong>Varianza:</strong> Se calcula como la integral de los cuadrados de las diferencias entre cada valor y el valor esperado, ponderado por la función de densidad de probabilidad.</p>
  <p><strong>Desviación Estándar:</strong> Es la raíz cuadrada positiva de la varianza.</p>

  <h4>3.2.4 Función Acumulada</h4>
  <p>La función acumulada <em>F(x)</em> de una variable aleatoria continua <em>X</em> se define como la integral de la función de densidad de probabilidad hasta <em>x</em>:</p>
  <p><em>F(x) = P(X ≤ x) = ∫−∞x f(t) dt</em></p>
  <p><strong>Uso:</strong> Permite calcular probabilidades acumuladas hasta un valor dado de la variable aleatoria continua.</p>

  <h4>3.2.5 Cálculos de Probabilidad</h4>
  <p>Para calcular la probabilidad de que una variable aleatoria continua caiga en un intervalo específico [<em>a, b</em>], se utiliza la función de densidad de probabilidad:</p>
  <p><em>P(a ≤ X ≤ b) = ∫ab f(x) dx</em></p>
  <p><strong>Uso:</strong> Determina la probabilidad de que la variable aleatoria caiga dentro de un rango específico de valores.</p>
</body>
</html>

<title>Tema 4: Distribuciones de Probabilidad</title>
<style>
  body {
    font-family: Arial, sans-serif;
    line-height: 1.6;
    margin: 20px;
  }
  h2 {
    color: #333;
  }
  p {
    margin-bottom: 15px;
  }
  .section {
    margin-bottom: 30px;
    border-bottom: 1px solid #ccc;
    padding-bottom: 20px;
  }
</style>
</head>
<body>
<h1>Tema 4: Distribuciones de Probabilidad</h1>

<div class="section">
  <h2>4.1 Función de Probabilidad</h2>
  <p>La función de probabilidad describe la relación entre los valores de una variable aleatoria y sus probabilidades correspondientes en el contexto de una distribución de probabilidad específica.</p>
  <p><strong>Explicación:</strong> Para una variable aleatoria discreta \( X \), la función de probabilidad \( P(X=x) \) asigna probabilidades a cada valor \( x \) que puede tomar \( X \).</p>
</div>

<div class="section">
  <h2>4.2 Distribución Binomial</h2>
  <p>La distribución binomial modela el número de éxitos en una secuencia de \( n \) ensayos independientes, donde cada ensayo tiene exactamente dos resultados posibles: éxito o fracaso.</p>
  <p><strong>Explicación:</strong> La probabilidad de exactamente \( k \) éxitos en \( n \) ensayos con probabilidad de éxito \( p \) está dada por:</p>
  <p>\[ P(X=k) = \binom{n}{k} p^k (1-p)^{n-k} \]</p>
  <p>donde \( \binom{n}{k} \) es el coeficiente binomial que representa el número de formas de elegir \( k \) éxitos entre \( n \) ensayos.</p>
</div>

<div class="section">
  <h2>4.3 Distribución Hipergeométrica</h2>
  <p>La distribución hipergeométrica modela el número de éxitos en una muestra de tamaño \( n \) extraída sin reemplazo de una población finita de tamaño \( N \), donde \( K \) son los elementos exitosos en la población.</p>
  <p><strong>Explicación:</strong> La probabilidad de exactamente \( k \) éxitos en la muestra está dada por:</p>
  <p>\[ P(X=k) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}} \]</p>
  <p>donde \( \binom{K}{k} \) es el número de formas de elegir \( k \) éxitos de \( K \) elementos y \( \binom{N-K}{n-k} \) es el número de formas de elegir \( n-k \) fallos de \( N-K \) elementos.</p>
</div>

<div class="section">
  <h2>4.4 Distribución de Poisson</h2>
  <p>La distribución de Poisson modela el número de eventos que ocurren en un intervalo de tiempo o espacio fijo, dado que los eventos ocurren a una tasa promedio constante y de manera independiente.</p>
  <p><strong>Explicación:</strong> La probabilidad de observar \( k \) eventos en un intervalo está dada por:</p>
  <p>\[ P(X=k) = \frac{\lambda^k e^{-\lambda}}{k!} \]</p>
  <p>donde \( \lambda \) es la tasa promedio de eventos por intervalo.</p>
</div>

<div class="section">
  <h2>4.5 Distribución Normal</h2>
  <p>La distribución normal, o gaussiana, es una de las distribuciones más importantes en estadística. Describe la distribución de una variable continua que es simétrica alrededor de su media, caracterizada por su media \( \mu \) y desviación estándar \( \sigma \).</p>
  <p><strong>Explicación:</strong> La función de densidad de probabilidad de una distribución normal está dada por:</p>
  <p>\[ f(x) = \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x-\mu)^2}{2 \sigma^2}} \]</p>
</div>

<div class="section">
  <h2>4.6 Distribución T-Student</h2>
  <p>La distribución T-Student se utiliza principalmente cuando el tamaño de la muestra es pequeño y se desconoce la desviación estándar de la población. Se utiliza en inferencia estadística para estimar intervalos de confianza y pruebas de hipótesis.</p>
  <p><strong>Explicación:</strong> La función de densidad de probabilidad de la distribución T-Student con \( \nu \) grados de libertad está dada por:</p>
  <p>\[ f(t) = \frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu \pi} \, \Gamma\left(\frac{\nu}{2}\right)} \left(1 + \frac{t^2}{\nu}\right)^{-\frac{\nu+1}{2}} \]</p>
</div>

<div class="section">
  <h2>4.7 Distribución Chi Cuadrada</h2>
  <p>La distribución Chi cuadrada se utiliza principalmente en pruebas de hipótesis y estimación de intervalos de confianza para la varianza de una población normalmente distribuida.</p>
  <p><strong>Explicación:</strong> La función de densidad de probabilidad de una distribución Chi cuadrada con \( \nu \) grados de libertad está dada por:</p>
  <p>\[ f(x) = \frac{1}{2^{\frac{\nu}{2}} \Gamma\left(\frac{\nu}{2}\right)} x^{\frac{\nu}{2}-1} e^{-\frac{x}{2}} \]</p>
</div>

<div class="section">
  <h2>4.8 Distribución F</h2>
  <p>La distribución F se utiliza en análisis de la varianza (ANOVA) y en pruebas de hipótesis sobre la igualdad de varianzas de dos poblaciones normales.</p>
  <p><strong>Explicación:</strong> La función de densidad de probabilidad de una distribución F con \( d_1 \) grados de libertad en el numerador y \( d_2 \) grados de libertad en el denominador está dada por:</p>
  <p>\[ f(x) = \frac{\Gamma\left(\frac{d_1 + d_2}{2}\right) \left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}} x^{\frac{d_1}{2} - 1}}{\Gamma\left(\frac{d_1}{2}\right) \Gamma\left(\frac{d_2}{2}\right) \left(1 + \frac{d_1 x}{d_2}\right)^{\frac{d_1 + d_2}{2}} } \]</p>
</div>

</body>
</html>

<title>Tema 5: Regresión Lineal</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
        }
        h1, h2, h3 {
            color: #333;
        }
        .section {
            margin-bottom: 20px;
        }
        .subsection {
            margin-bottom: 10px;
        }
        .explanation {
            margin-left: 20px;
        }
    </style>
</head>
<body>
    <h1>TEMA 5: Regresión Lineal</h1>

    <div class="section">
        <h2>5.1 Regresión y Correlación</h2>

        <div class="subsection">
            <h3>5.1.1 Diagrama de Dispersión</h3>
            <div class="explanation">
                <p>Un diagrama de dispersión es una representación gráfica de pares de datos (x, y), donde cada punto representa una observación. Es útil para visualizar la relación entre dos variables y detectar patrones como tendencias, agrupaciones o dispersión.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.2 Regresión Lineal Simple</h3>
            <div class="explanation">
                <p>La regresión lineal simple modela la relación entre una variable independiente <em>x</em> y una variable dependiente <em>y</em> mediante una ecuación lineal de la forma <em>y = β₀ + β₁x + ϵ</em>, donde <em>β₀</em> y <em>β₁</em> son los coeficientes de la regresión y <em>ϵ</em> es el término de error.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.3 Correlación</h3>
            <div class="explanation">
                <p>La correlación cuantifica la fuerza y dirección de la relación lineal entre dos variables. El coeficiente de correlación de Pearson <em>r</em> es una medida común que varía entre -1 y 1, donde 1 indica una correlación positiva perfecta, -1 una correlación negativa perfecta y 0 una falta de correlación lineal.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.4 Determinación y Análisis de los Coeficientes de Correlación y de Determinación</h3>
            <div class="explanation">
                <p>El coeficiente de determinación <em>R²</em> es una medida que indica qué porcentaje de la variabilidad de la variable dependiente puede ser explicada por la variable independiente en el modelo de regresión. Se calcula como <em>R² = 1 - (SSres / SStot)</em>, donde <em>SSres</em> es la suma de los cuadrados de los residuos y <em>SStot</em> es la suma total de los cuadrados.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.5 Distribución Normal Bidimensional</h3>
            <div class="explanation">
                <p>La distribución normal bidimensional describe la distribución conjunta de dos variables aleatorias continuas, donde cada variable sigue una distribución normal univariada. La función de densidad de probabilidad bidimensional se define en términos de la media, la varianza y el coeficiente de correlación entre las dos variables.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.6 Intervalos de Confianza y Pruebas para el Coeficiente de Correlación</h3>
            <div class="explanation">
                <p>Los intervalos de confianza para el coeficiente de correlación <em>r</em> permiten estimar el rango plausible de valores para <em>r</em> en la población. Las pruebas de hipótesis se utilizan para determinar si el coeficiente de correlación observado es estadísticamente significativo.</p>
            </div>
        </div>

        <div class="subsection">
            <h3>5.1.7 Errores de Medición</h3>
            <div class="explanation">
                <p>Los errores de medición son discrepancias entre el valor medido de una variable y su valor verdadero. En el contexto de la regresión lineal, los errores de medición afectan la precisión del modelo y pueden introducir sesgos y errores estándar.</p>
            </div>
        </div>

    </div>

</body>
</html>